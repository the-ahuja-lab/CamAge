{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Notebook for using CamAge model weights to re-train any datasetage related dataset####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing useful libraries\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score,recall_score , precision_score , classification_report , f1_score,roc_auc_score,average_precision_score,confusion_matrix\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision.models import Inception3\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_folder = \"/CPT_Dataset/\"): ## here path to dataset suer want to train (Use CPT dataset from zenodo for trail )\n",
    "    dataset = []\n",
    "    list_of_class = os.listdir(data_folder)\n",
    "  \n",
    "    for class_name in list_of_class:\n",
    "        class_folder = os.path.join(data_folder,class_name)\n",
    "        if not os.path.isfile(class_folder):\n",
    "            list_of_images = os.listdir(class_folder)\n",
    "            if \"CPT1\" in class_name:\n",
    "                list_of_images = random.sample(list_of_images,k =1863)\n",
    "            elif \"CPT2\" in class_name:\n",
    "                list_of_images = random.sample(list_of_images,k = 2415)\n",
    "            elif \"CPT3\" in class_name:\n",
    "                list_of_images = random.sample(list_of_images,k = 2418)\n",
    "            elif \"CPT4\" in class_name:\n",
    "                list_of_images = random.sample(list_of_images,k = 2324)\n",
    "            elif \"CPT5\" in class_name:\n",
    "                list_of_images = random.sample(list_of_images,k = 2086)\n",
    "            elif \"Untreated\" in class_name:\n",
    "                list_of_images = random.sample(list_of_images,k = 3901)\n",
    "\n",
    "\n",
    "\n",
    "            for image in tqdm(list_of_images):\n",
    "                if image.endswith(\"jpg\") or image.endswith(\"jpeg\") or image.endswith(\"png\"):\n",
    "                    image_path = os.path.join(class_folder , image)\n",
    "                    dataset.append(dict(image_path = image_path ,class_name = class_name))\n",
    "    dataset = pd.DataFrame(dataset)\n",
    "    return dataset\n",
    "dataset = read_data()\n",
    "class_numeric = {\"Untreated\" : 0,\"CPT1\" : 1 , \"CPT2\" : 2, \"CPT3\" : 3, \"CPT4\" : 4, \"CPT5\" : 5}\n",
    "\n",
    "\n",
    "dataset[\"class_name\"] = dataset[\"class_name\"].apply(lambda x : class_numeric[x])\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make coustom dataset and data loader\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,x,y,transform):\n",
    "        super(CustomDataset,self).__init__()\n",
    "        self.x = list(x)\n",
    "        self.y = list(y)\n",
    "        self.transform = transform \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self,index):\n",
    "        image = self.x[index]\n",
    "        \n",
    "        image = Image.open(image).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "#         image_name = os.path.basename(image)\n",
    "#         label = self.y[index].item()  \n",
    "        return (image , torch.tensor(self.y[index],dtype = torch.long))\n",
    "def get_dataloader(dataset,image_resize,batch_size):\n",
    "    x_train,x_test,y_train,y_test = train_test_split(dataset[\"image_path\"],dataset[\"class_name\"],test_size = 0.25,stratify=dataset[\"class_name\"])\n",
    "    transform = transforms.Compose([transforms.ToTensor(),transforms.Resize(image_resize),transforms.RandomHorizontalFlip(),transforms.RandomVerticalFlip(),\n",
    "                                transforms.Normalize(mean = (0.485, 0.456, 0.406),std = (0.229, 0.224, 0.225)),\n",
    "                                ])\n",
    "    train_dataset = CustomDataset(x_train,y_train,transform)\n",
    "    test_dataset = CustomDataset(x_test,y_test,transform)\n",
    "    train_dataloader = DataLoader(dataset = train_dataset , batch_size = batch_size , shuffle = True)\n",
    "    test_dataloader = DataLoader(dataset = test_dataset , batch_size = batch_size, shuffle = True)\n",
    "    return train_dataloader,test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model structure\n",
    "\n",
    "class ImageInceptionResNetV2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageInceptionResNetV2, self).__init__()\n",
    "        self.image_feature_extractor = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=1000, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_features=128, out_features=10),\n",
    "            nn.Softmax(dim=1))\n",
    "    def forward(self, x):\n",
    "        \n",
    "        inception_outputs = self.image_feature_extractor(x)\n",
    "        output = inception_outputs\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TrainModel:\n",
    "    def __init__(self,model,dataset,batch_size,n_epochs,image_resize,lr,model_name):\n",
    "        self.model_name = model_name\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.n_epochs = n_epochs\n",
    "        self.image_resize = image_resize\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.train_dataloader,self.test_dataloader = get_dataloader(self.dataset,self.image_resize,\n",
    "                                                                    self.batch_size)\n",
    "        self.model = model.to(self.device)\n",
    "        self.lr = lr\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(),lr = self.lr)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "    def train_test(self):\n",
    "        \n",
    "        for epoch in range(self.n_epochs):\n",
    "            image_names = [item for item in self.test_dataloader.dataset.x]\n",
    "#             print(image_names)\n",
    "            epoch_image_names_file = f\"epoch_{epoch}_image_names.txt\"  \n",
    "          \n",
    "            with open(epoch_image_names_file, 'w') as f:\n",
    "            \tf.write('\\n'.join(image_names))\n",
    "#             \tprint(f\"Saved image names for epoch {epoch} to {epoch_image_names_file}\")\n",
    "            \n",
    "\n",
    "            image_names = [item for item in self.train_dataloader.dataset.x]\n",
    "            epoch_image_names_file_train = f\"epoch_{epoch}_image_names_train.txt\"            \n",
    "            with open(epoch_image_names_file_train, 'w') as f:\n",
    "            \tf.write('\\n'.join(image_names))\n",
    "#             \tprint(f\"Saved image names for epoch {epoch} to {epoch_image_names_file_train}\")\n",
    "\n",
    "    \n",
    "            total_loss_train = 0.0\n",
    "            self.ground_truth = []\n",
    "            self.prediction = []\n",
    "            self.probability = []\n",
    "            for index,(image_train,image_test) in enumerate(zip(self.train_dataloader,self.test_dataloader)):\n",
    "                train_image = image_train[0].to(self.device)\n",
    "                train_label = image_train[1].to(self.device)\n",
    "                self.model.zero_grad()\n",
    "                output_train = self.model(train_image)\n",
    "                loss_train = self.criterion(output_train , train_label)\n",
    "                loss_train.backward()\n",
    "                total_loss_train += loss_train.item()\n",
    "                self.optimizer.step()\n",
    "                if(index % 10 == 0):\n",
    "                    print(\"|EPOCH : {0}|{1},BATCH : {2}|{3} , LOSS train: {4}\".format(epoch+1,self.n_epochs,index,len(self.train_dataloader),total_loss_train))\n",
    "              #print(\".....................Training End......................\")\n",
    "              #print(\".....................Testing Start.....................\")\n",
    "                test_image = image_test[0].to(self.device)\n",
    "                test_label= image_test[1].to(self.device)\n",
    "                self.model.zero_grad()\n",
    "                output_test = self.model(test_image)\n",
    "                pred = torch.argmax(output_test,dim=1).cpu().tolist()\n",
    "                self.ground_truth.extend(test_label.tolist())\n",
    "                self.prediction.extend(pred)\n",
    "                self.probability.extend(output_test.cpu().tolist())\n",
    "              #if(index % 10 == 0):\n",
    "                 # print(\"|BATCH : {0}|{1}\".format(index,len(self.test_dataloader)))\n",
    "              #print(\".....................Testing End......................\") \n",
    "            self.probability = np.array(self.probability)\n",
    "            self.one_hot_encoding = list()\n",
    "            for label in self.ground_truth:\n",
    "                vector = [0,0,0,0,0,0]\n",
    "                vector[label] = 1\n",
    "                self.one_hot_encoding.append(vector)\n",
    "            self.one_hot_encoding = np.array(self.one_hot_encoding)\n",
    "            average_precision = dict()\n",
    "            ground_truth_file = \"ground_truth_epoch{}.npy\".format(epoch)\n",
    "            probability_file = \"predicted_probabilities_epoch{}.npy\".format(epoch)\n",
    "            np.save(ground_truth_file, np.array(self.ground_truth))\n",
    "            np.save(probability_file, np.array(self.probability))\n",
    "            for i in range(6):\n",
    "                average_precision = average_precision_score(self.one_hot_encoding[:,i],self.probability[:,i])\n",
    "                torch.save(self.model.state_dict(),os.path.join(\"model_epoch{}.pt\".format(epoch)))\n",
    "                Classification_report_dataframe = pd.DataFrame()\n",
    "                Classification_report_dataframe['Accuracy Score'] = accuracy_score(self.ground_truth,self.prediction)*100\n",
    "                Classification_report_dataframe['Reacll Score'] = recall_score(self.ground_truth,self.prediction,average = \"weighted\")*100\n",
    "                Classification_report_dataframe['Precision'] = precision_score(self.ground_truth,self.prediction,average = \"weighted\")*100\n",
    "                Classification_report_dataframe['F1 Score'] = f1_score(self.ground_truth,self.prediction,average = \"weighted\")*100\n",
    "                Classification_report_dataframe['ROC_AUC Score'] = roc_auc_score(self.ground_truth,self.probability,multi_class = \"ovo\")*100\n",
    "              #Classification_report_dataframe['Average Precision'] =  np.mean(list(average_precision.values()))*100\n",
    "              #\n",
    "              #Classification_report_dataframe.to_csv(\"Classification_report_dataframe\"+str(epoch)+\".csv\")\n",
    "                print(\"Epoch Report.....>>>>>>>>>>>>>>>>\",epoch)\n",
    "\n",
    "\n",
    "                print(\"Accuracy : \",accuracy_score(self.ground_truth,self.prediction)*100)\n",
    "                print(\"Recall : \",recall_score(self.ground_truth,self.prediction,average = \"weighted\")*100)\n",
    "                print(\"Precision : \",precision_score(self.ground_truth,self.prediction,average = \"weighted\")*100)\n",
    "                print(\"F1_Score : \",f1_score(self.ground_truth,self.prediction,average = \"weighted\")*100)\n",
    "                print(\"ROC AUC Score : \",roc_auc_score(self.ground_truth,self.probability,multi_class = \"ovo\")*100)\n",
    "              #print(\"AUPRC :\" , np.mean(list(average_precision.values()))*100)\n",
    "                print(\"Classification Report : \")\n",
    "                print(classification_report(self.ground_truth,self.prediction))\n",
    "                Classification_report = classification_report(self.ground_truth,self.prediction)\n",
    "              #Classification_report.to_csv(\"Classification_report\"+str(epoch)+\".csv\")\n",
    "            res = []\n",
    "            for l in [0,1,2,3,4,5]:\n",
    "                prec,recall,_,_ = precision_recall_fscore_support(np.array(self.ground_truth)==l,\n",
    "                                                                  np.array(self.prediction)==l,\n",
    "                                                                  pos_label=True,average=None)\n",
    "                res.append(recall[1])\n",
    "            print(\"Specificity : \",np.mean(res)*100)\n",
    "            Classification_report_dataframe['Specificity'] = np.mean(res)*100\n",
    "\t  #print(Classification_report_dataframe)\n",
    "\n",
    "\n",
    "    def train_test_dl_model(self):\n",
    "        self.train_test()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load Pre-trained Model with User's Weights\n",
    "model = ImageInceptionResNetV2()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "weights_path = \"/storage/subhadeepd/CamAge/Images/Phase_Contrast_Images/Refined_Models/10_Label_Based/IR_05_09_23/Final_model_full_data/model_epoch200.pt\"\n",
    "model.load_state_dict(torch.load(weights_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Modify Model Output Layer\n",
    "class ImageInceptionResNetV2Modified(nn.Module):\n",
    "    def __init__(self, pretrained_model, num_classes):\n",
    "        super(ImageInceptionResNetV2Modified, self).__init__()\n",
    "        self.image_feature_extractor = pretrained_model.image_feature_extractor  # Use the same feature extractor\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=1000, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_features=128, out_features=num_classes),  # Modify output features to the number of classes\n",
    "            nn.Softmax(dim=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        inception_outputs = self.image_feature_extractor(x)\n",
    "        output = inception_outputs\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "# Instantiate and load weights into the modified model\n",
    "num_classes = 6  # Specify the number of classes in your dataset\n",
    "modified_model = ImageInceptionResNetV2Modified(model, num_classes)\n",
    "# modified_model.load_state_dict(torch.load(weights_path), strict=False)  # Load weights into the modified model, set strict=False to ignore mismatched parameters\n",
    "\n",
    "# If you want to initialize the last fully connected layer of the modified model with random weights instead of using the pre-trained weights, you can uncomment the following line\n",
    "# modified_model.fc[4] = nn.Linear(128, num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Here user can chaneg the number of epochs, batch size and learning rate\n",
    "\n",
    "os.chdir(\"path/to working /directory\")\n",
    "train_model = TrainModel(model = modified_model,dataset = dataset,\n",
    "                         batch_size = 32,n_epochs=500,image_resize = (299, 299),\n",
    "                         lr = 0.0001,model_name = \"trained_new_model.pt\")\n",
    "train_model.train_test_dl_model()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CamAge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
