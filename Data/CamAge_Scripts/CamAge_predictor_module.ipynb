{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing useful libraries\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision.models import Inception3\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from functools import reduce\n",
    "import random\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sys\n",
    "import seaborn as sns\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "# import Explainer function from lime_tabular module of lime library\n",
    "# from lime.lime_tabular import LimeTabularExplainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def perform_contour_analysis(dir_raw, dir_mask, dir_contour, out_dir):\n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    \n",
    "    # Initialize lists to store contour properties\n",
    "    Countour_area = []\n",
    "    Arc_length = []\n",
    "    Covexity = []\n",
    "    convexhull = []\n",
    "    Name = []\n",
    "\n",
    "    # Loop over files in dir_mask\n",
    "    for file in sorted(os.listdir(dir_mask)):\n",
    "        if file.endswith(\".jpg\"):\n",
    "            print(\"Processing file:\", file)\n",
    "            # Read masked image\n",
    "            mask = cv2.imread(os.path.join(dir_mask, file))\n",
    "            mask[mask > 0] = 255  # Thresholding\n",
    "            \n",
    "            # Find contours\n",
    "            contours, _ = cv2.findContours(cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            # Loop over contours\n",
    "            for i, c in enumerate(contours):\n",
    "                if cv2.minEnclosingCircle(c)[1] >= 50 and cv2.minEnclosingCircle(c)[1] <= 1000:\n",
    "                    rect = cv2.boundingRect(c)\n",
    "                    x, y, w, h = rect\n",
    "                    if rect[2] <= 50 or rect[3] <= 50:\n",
    "                        continue\n",
    "                    if cv2.contourArea(c) >= 1000 and cv2.contourArea(c) <= 100000:\n",
    "                        if cv2.arcLength(c, True) >= 240 and cv2.arcLength(c, True) <= 20000:\n",
    "                            # Extract ROI\n",
    "                            ROI = cv2.imread(os.path.join(dir_raw, file))[y:y+h+10, x:x+w-10]\n",
    "                            \n",
    "                            # Append contour properties to lists\n",
    "                            Countour_area.append(cv2.minEnclosingCircle(c)[1])\n",
    "                            Arc_length.append(cv2.arcLength(c, True))\n",
    "                            Covexity.append(cv2.isContourConvex(c))\n",
    "                            convexhull.append(cv2.convexHull(c))\n",
    "                            Name.append(os.path.join(dir_contour, '{}_ROI_{}.png'.format(file.split('.')[0], i)))\n",
    "                            \n",
    "                            # Save ROI image\n",
    "                            cv2.imwrite(os.path.join(dir_contour, '{}_ROI_{}.png'.format(file.split('.')[0], i)), ROI)\n",
    "            \n",
    "    # Create DataFrame with contour properties\n",
    "    contour_Data = pd.DataFrame({\n",
    "        \"Countour_Area\": Countour_area,\n",
    "        \"Perimeter\": Arc_length,\n",
    "        \"Is_Convex\": Covexity,\n",
    "        \"Convexhull\": convexhull,\n",
    "        \"Name\": Name\n",
    "    })\n",
    "    \n",
    "    # Save DataFrame to CSV\n",
    "    contour_Data.to_csv(os.path.join(out_dir, 'contour_results.csv'), index=False)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    dir_raw = \"\"  ## input directory path of raw images\n",
    "    dir_mask = \"\"  ## output directory path of segmented image/masks\n",
    "   \n",
    "    dir_contour = \"\"   ## new dir file path\n",
    "    out_dir = \"\"         ## new dir file path\n",
    "\n",
    "    perform_contour_analysis(dir_raw, dir_mask, dir_contour, out_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### To load Ca,Age model\n",
    "class ImageInceptionResNetV2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageInceptionResNetV2, self).__init__()\n",
    "        self.image_feature_extractor = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=1000, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_features=128, out_features=10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        inception_outputs = self.image_feature_extractor(x)\n",
    "        output = inception_outputs\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "### To prerocess data\n",
    "def get_preprocess_transform():\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])     \n",
    "    transf = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])    \n",
    "\n",
    "    return transf    \n",
    "\n",
    "### Batch prediction\n",
    "def batch_predict(model, images):\n",
    "    model.eval()\n",
    "    preprocess_transform = get_preprocess_transform()\n",
    "    transform2 = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    batch = torch.stack(tuple(transform2(i) for i in images), dim=0)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    batch = batch.to(device)\n",
    "    logits = model(batch)\n",
    "    probs = logits#.argmax(dim=1)\n",
    "    return probs.detach().cpu().numpy()\n",
    "\n",
    "### For explanability module\n",
    "def explanation_heatmap(exp, exp_class, output_path=None):\n",
    "    dict_heatmap = dict(exp.local_exp[exp_class])\n",
    "    heatmap = np.vectorize(dict_heatmap.get)(exp.segments) \n",
    "    plt.imshow(heatmap, cmap='RdBu', vmin=-heatmap.max(), vmax=heatmap.max())\n",
    "    plt.colorbar()\n",
    "    if output_path:\n",
    "        plt.savefig(output_path)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    " ### Prediction_model       \n",
    "def process_image_data(input_path, output_path):\n",
    "    dirname = os.path.dirname(__file__)\n",
    "    model_path = os.path.join(dirname, 'Model/model_epoch200.pt')\n",
    "    bioactivity_model_path = os.path.join(dirname, 'Models/Bioactivity_full_trained_models/rr_TMRE_regression.sav')\n",
    "\n",
    "    with open(os.path.join(dirname, 'Models/Bioactivity_full_trained_models/rr_TMRE_regression.sav'), 'rb') as file:\n",
    "        TMRE = pickle.load(file)\n",
    "        \n",
    "    with open(os.path.join(dirname, 'Models/Bioactivity_full_trained_models/rr_H2DCFDA_regression.sav'), 'rb') as file:\n",
    "        H2DCFDA = pickle.load(file)\n",
    "\n",
    "    with open(os.path.join(dirname, 'Models/Bioactivity_full_trained_models/rr_FM4_46_regression.sav'), 'rb') as file:\n",
    "        FM4_46 = pickle.load(file)\n",
    "\n",
    "    with open(os.path.join(dirname, 'Models/Drugs_full_trained_model/rf_MG132_Classification.sav'), 'rb') as file:\n",
    "        MG132 = pickle.load(file)\n",
    "        \n",
    "    with open(os.path.join(dirname, 'Models/Drugs_full_trained_model/rf_Azacytidine_Classification.sav'), 'rb') as file:\n",
    "        Aza = pickle.load(file)\n",
    "        \n",
    "    with open(os.path.join(dirname, 'Models/Drugs_full_trained_model/rf_Etoposide_Classification.sav'), 'rb') as file:\n",
    "        Etoposide = pickle.load(file)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir(input_path):\n",
    "        \n",
    "        data3 = pd.DataFrame()\n",
    "        print(i)\n",
    "        data = pd.read_csv(os.path.join(input_path, i))\n",
    "        data2 = data.drop([\"Names\"], axis=1) #name col, feat col (1-128 list) - 2 cols + 1-128 col, data2 has 128 cols\n",
    "        \n",
    "        data2_pred = TMRE.predict(data2)\n",
    "        data3[\"Prediction_TMRE_Intensity\"] = data2_pred\n",
    "        \n",
    "        data2_pred = H2DCFDA.predict(data2)\n",
    "        data3[\"Prediction_H2DCFDA_Intensity\"] = data2_pred\n",
    "        \n",
    "        data2_pred = FM4_46.predict(data2)\n",
    "        data3[\"Prediction_FM_Intensity\"] = data2_pred\n",
    "        \n",
    "        data2_pred = MG132.predict(data2)\n",
    "        data3[\"MG132\"] = data2_pred\n",
    "        \n",
    "        data2_pred = Aza.predict(data2)\n",
    "        data3[\"Azacytidine\"] = data2_pred\n",
    "        \n",
    "        data2_pred = Etoposide.predict(data2)\n",
    "        data3[\"Etoposide\"] = data2_pred    \n",
    "\n",
    "        data3[\"Names\"] = data[\"Names\"]\n",
    "        \n",
    "        item_name = \"_\".join(i.split(\"_\")[2:-1])\n",
    "\n",
    "        print(\"i:\", i)\n",
    "        print(\"item_name:\", item_name)\n",
    "        output_file = os.path.join(output_path, \"predictions_\" + item_name + i.split(\"_\")[2] + '.csv')\n",
    "        print(output_file) \n",
    "        data3.to_csv(output_file, index=False)\n",
    "\n",
    "def predict_images(input_folder, output_folder, explainability=False, num_features=3, image_features=False, ko_prediction=False):\n",
    "    # check_and_download_models()\n",
    "    model = ImageInceptionResNetV2()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    dirname = os.path.dirname(__file__)\n",
    "    model_path = os.path.join(dirname, 'model_epoch200.pt')\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # input_folder = os.path.join(output_folder, 'Test_Images')\n",
    "    names_images = []\n",
    "    label = []\n",
    "    all_prob = []\n",
    "    test_prob = []\n",
    "    \n",
    "    for image_file in os.listdir(input_folder):\n",
    "        if image_file.endswith('.png') or image_file.endswith('.jpg'):\n",
    "            image_path = os.path.join(input_folder, image_file)\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            image = transform(image)\n",
    "            image = image.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "            # Move input tensor to GPU if available\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            image = image.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(image)\n",
    "\n",
    "            prediction = output.argmax(dim=1)\n",
    "            label.append(prediction)\n",
    "            names_images.append(image_file)\n",
    "\n",
    "            probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "            prediction = output.argmax(dim=1)\n",
    "            predicted_class = prediction.item()\n",
    "            predicted_probability = probabilities[0, predicted_class].item()\n",
    "            all_probabilities = probabilities[0].tolist()\n",
    "            test_prob.append(predicted_probability)\n",
    "            all_prob.append(all_probabilities)\n",
    "\n",
    "    print('*****************Saving Image Predictions start****************')\n",
    "    Image_predictions = pd.DataFrame()\n",
    "    Image_predictions[\"File Name\"] = names_images\n",
    "    Image_predictions[\"Label\"] = pd.DataFrame(label)\n",
    "    Image_predictions[\"Predicted_class_prob\"] = test_prob\n",
    "    Image_predictions[\"All_class_prob\"] = all_prob\n",
    "    Image_predictions.to_csv(os.path.join(output_folder, \"Test_Image_predictions.csv\"))\n",
    "    print('*****************End Saving Image Predictions start****************')\n",
    "\n",
    "    if explainability:\n",
    "        print(\"EXPLAINABILITY\")\n",
    "        explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "        def predict_fn(images):\n",
    "            return batch_predict(model, images)\n",
    "\n",
    "        for image_file in os.listdir(input_folder):\n",
    "            if image_file.endswith('.png') or image_file.endswith('.jpg'):\n",
    "                image = Image.open(os.path.join(input_folder, image_file)).convert(\"RGB\")\n",
    "                preprocessed_image = transform(image)\n",
    "                input_image = preprocessed_image.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "                explanation = explainer.explain_instance(input_image[0].permute(1, 2, 0).numpy(),\n",
    "                                                         predict_fn,\n",
    "                                                         top_labels=10,\n",
    "                                                         hide_color=0,\n",
    "                                                         num_samples=1000)\n",
    "\n",
    "                transform3 = transforms.Compose([\n",
    "                    transforms.Resize((299, 299)),\n",
    "                    transforms.ToTensor(),\n",
    "                ])\n",
    "                original_image = image.copy()\n",
    "                original_image  =  transform3(original_image)\n",
    "                original_image  = original_image.permute(1,2,0)\n",
    "                \n",
    "                pdf_path1 = os.path.join(output_folder, f'{image_file}_F1_boundary1.pdf')\n",
    "                fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "                temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=50, hide_rest=False)\n",
    "                img_boundry1 = mark_boundaries(np.array(original_image), mask)\n",
    "\n",
    "                # temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True,\n",
    "                #                                             num_features=50, hide_rest=False)\n",
    "                # img_boundry1 = mark_boundaries(np.array(preprocessed_image.permute(1, 2, 0)), mask)\n",
    "                fig = plt.figure(figsize=(15, 5))\n",
    "                \n",
    "                plt.imshow(img_boundry1)\n",
    "                plt.title('Image with Boundaries')\n",
    "                plt.savefig(pdf_path1)\n",
    "                plt.close()\n",
    "                \n",
    "                pdf_path2 = os.path.join(output_folder, f'{image_file}_F1_boundary2.pdf')\n",
    "\n",
    "                temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=num_features, hide_rest=False)\n",
    "                plt.imshow(mark_boundaries(np.array(original_image)/ 2 + 0.5, mask))\n",
    "                plt.title('Explanation Image')\n",
    "                plt.savefig(pdf_path2)\n",
    "                \n",
    "                heatmap_path = os.path.join(output_folder, f'{image_file}_F1_heatmap.pdf')\n",
    "\n",
    "                # heatmap_path = os.path.join(output_folder, f'{image_file}_heatmap.pdf')\n",
    "                explanation_heatmap(explanation, explanation.top_labels[0], heatmap_path) #option top label upto 9\n",
    "                plt.close()\n",
    "\n",
    "    if image_features:\n",
    "        print(\"FEATURES\")\n",
    "        # for i in os.listdir(main_folder):\n",
    "        #     input_folder = os.path.join(main_folder, i)\n",
    "            \n",
    "        # Check if the item is a directory\n",
    "        if os.path.isdir(input_folder):\n",
    "            print(\"input_folder:\", input_folder)\n",
    "\n",
    "            # Initialize lists to store features and image names\n",
    "            all_features = []\n",
    "            all_names = []\n",
    "\n",
    "            # Loop over all the items in the input folder\n",
    "            for item in sorted(os.listdir(input_folder)):\n",
    "                print(\"item:\", item)\n",
    "                item_path = os.path.join(input_folder, item)\n",
    "                \n",
    "                x = item_path  \n",
    "                if x.endswith('.jpg') or x.endswith('.png'):\n",
    "                    # Load the image\n",
    "                    image_path = item_path\n",
    "                    image = Image.open(image_path).convert('RGB')\n",
    "                    # Apply the transformation and send the image to the device\n",
    "                    input_tensor = transform(image).unsqueeze(0)\n",
    "                    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "                    input_tensor = input_tensor.to(device)\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        output = model.fc[0](model.image_feature_extractor(input_tensor))\n",
    "                    flattened_features = torch.flatten(output)\n",
    "                    \n",
    "                    output = output.cpu()\n",
    "                    numpy_features = output.numpy()\n",
    "\n",
    "                    # Append features and image name to lists\n",
    "                    all_features.append(list(numpy_features[0]))\n",
    "                    all_names.append(item_path)\n",
    "\n",
    "            # Create DataFrame\n",
    "            column_names = [\"Names\"] + [f\"{i+1}\" for i in range(len(all_features[0]))]\n",
    "            data = [[name] + features for name, features in zip(all_names, all_features)]\n",
    "            formatted_feature_file = pd.DataFrame(data, columns=column_names)\n",
    "\n",
    "            # Save to CSV\n",
    "            out_path = os.path.join(output_folder, f'all_images_data_{item}.csv')\n",
    "            print(\"Saving at:\", out_path)\n",
    "            formatted_feature_file.to_csv(out_path, index=False)\n",
    "\n",
    "            print(\"ko prediction: \", ko_prediction)\n",
    "            if ko_prediction:\n",
    "                print(\"calling function\")\n",
    "                process_image_data(output_folder, output_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_folder = 'Path/to/input folder'  ## output folder of perform_contour_analysis\n",
    "output_folder = 'Path/to/output folder' ## user defined \n",
    "\n",
    "\n",
    "predict_images(input_folder, output_folder, explainability=True, num_features=3, image_features=True)## use False if any of the features not required\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
